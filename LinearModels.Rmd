---
title: "SDMTSA_Project_LinearModels"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


Carico le librerie necessarie allo svolgimento del progetto
```{r}
library(forecast)
library(KFAS)
library(tidyverse)
library(ggplot2)
library(xts)
library(urca)
library(plotly)
library(naniar)
library(prophet)
library(tseries)
library(fastDummies)
library(bizdays)
library(RQuantLib)
library(lubridate)
library(reticulate)
library(tsfknn)
library(keras)
library(skmeans)
library(tsfknn)
library(recipes)
library(tibbletime)
library(MLmetrics)
library(timeSeries)
```


Leggo il dataset
```{r}
data <- read.csv2("time_series_dataset.csv", dec = ".")
data$Data <- as.Date(data$Data, format = '%Y-%m-%d')
print(head(data))
```


Calcolo del lambda della trasformazione di Box Cox
```{r}
BoxCox.lambda(data$value)
```
Dato che il valore di lambda è prossimo a 1, si deduce che non è necessario applicare una trasformazione ai dati.


Semplice visualizzazione dei dati
```{r}
ggplot(data,aes(x=Data, y=value)) +
  geom_line() +
  stat_smooth(method = "lm", se = T, col="red", level=0.99)+
  xlab("Time") +
  ylab("Value")
  
```

Dalla visualizzazione si conferma quanto già suggerito dal valore di lambda, e cioè che non c'è una relazione lineare tra media e varianza della serie storica. Sembra però esserci della stagionalità di cui tener conto.




########################## ARIMA ########################## 




Visualizziamo i correlogrammi:
```{r, fig.width=12, fig.height=5}
ts <- xts(data$value, start=c(2010,1), order.by=data$Data)  #trasformo i dati in x time series

par(mfrow=c(1,2))
Acf(ts,lag.max = 80) 
Pacf(ts,lag.max = 80)
```

I correlogrammi mostrano la presenza di una stagionalità. In particolare, guardando al PACF sembra che vi sia una stagionalità settimanale.


In base a quanto osservato, provo a porre una differenza stagionale di periodo 7 alla serie:
```{r, fig.width=12, fig.height=8}
ggtsdisplay(diff(ts, 7),points = FALSE,lag.max = 80)
```


Divido il dataset in train set e test set. Di quest'ultimo faranno parte i dati degli ultimi due anni.
```{r}
# dati come xts
train <- ts["2010-01-01/2016-12-31"]
test <- ts["2017-01-01/2018-12-31"] 
shift <- ts["2016-01-01/2016-12-31"]

#dati come ts per produrre i grafici successivamente
train_ts <- ts(train, start = 1, end = length(train),frequency = frequency(train)) 
test_ts <- ts(test, start = length(train)+1, end = length(test)+length(train),frequency = frequency(test))
shift_ts <- ts(shift, start = length(ts["2010-01-01/2016-01-01"])+1, end = length(shift)+length(ts["2010-01-01/2016-01-01"])+1,frequency = frequency(shift))


#dati come df
traindf <- data %>%  dplyr::filter(Data <= ymd("2016-12-31"))
testdf <- data %>%  dplyr::filter(Data > ymd("2016-12-31"))

```


```{r, fig.width=12, fig.height=6}
rbind(data.frame(Date=index(train), value=coredata(train), set="train"),
     data.frame(Date=index(test), value=coredata(test), set="test")) %>%
    ggplot(aes(x=Date, y=value)) +
        geom_line(aes(colour = set)) +
        stat_smooth(method = "lm", se = T, col="blue", level=0.99)
```


```{r, fig.width=12, fig.height=6}
cat("percentuale di osservazioni nel training set: ", length(train)/length(ts))
cat("\npercentuale di osservazioni nel test set: ", length(test)/length(ts))
```


Proviamo considerando un modello che tenga conto della stagionalità si periodo 7 della serie
```{r, fig.height=9}
mod1 <- Arima(train, c(0,0,0), list(order=c(1,1,1), period=7), lambda = "auto")
ggtsdisplay(mod1$residuals, lag.max = 80)
summary(mod1)
```
I coefficienti del modello sembrano essere significativi; inoltre, dai correlogrammi dei residui del modello, risultano esserci diverse componenti da prendere in considerazione. In particolare, l'ACF suggerirebbe la presenza di una componente MA(6) dati i primi 6 lag. Sono presenti anche altre componenti che ricercheremo successivamente. 


Provo a procedere "verticalmente": si confrontano modelli con diversi parametri in termini di log-likelihood AIC e BIC. Quello che risulterà essere migliore sarà utilizzato come base su cui continuare il lavoro.
```{r}
# I modelli arima con un elevato numero di coefficienti nei doppi cicli danno errori

for (j in 1:7){
  mod<-Arima(train, c(j,0,5),list(order = c(1,1,1), period = 7),lambda = "auto")
  cat("\nModello AR(",j,") MA( 5 )  --- log-lik:",mod$loglik,"--- aic:",mod$aic)
}

for (j in 1:7){
  mod<-Arima(train, c(j,0,6),list(order = c(1,1,1), period = 7),lambda = "auto")
  cat("\nModello AR(",j,") MA( 6 )  --- log-lik:",mod$loglik,"--- aic:",mod$aic)
}

for (j in 1:7){
  mod<-Arima(train, c(j,0,7),list(order = c(1,1,1), period = 7),lambda = "auto")
  cat("\nModello AR(",j,") MA( 7 )  --- log-lik:",mod$loglik,"--- aic:",mod$aic)
}


```
Il modello ARMA(6,7) come quello ottimale sia in termini di log-likelihood che in termini di AIC. 


Continuiamo quindi con l'ARIMA(6,0,7)(1,1,1)[7]. 
```{r, fig.height=9}
mod2 <- Arima(train, c(6,0,7), list(order=c(1,1,1), period=7), lambda = "auto")
ggtsdisplay(mod2$residuals, lag.max = 80)
summary(mod2)

```
Ora, dall'analisi dei correlogrammi, è soprattutto il lag 20 a risultare significativamente diverso da 0.


Proviamo ad analizzare le radici dell'equazione caratteristica del modello:
```{r}
autoplot(mod2)
Mod(1/polyroot(c(1,-mod2$coef[1:6])))
```
Dall'analisi, non sembra essere necessaria alcuna integrazione alla componente non stagionale.


Per completezza proviamo a vedere cosa succede procedendo con un'integrazione:
```{r}
mod3 <- Arima(train, c(6,1,7), list(order=c(1,1,1), period=7), lambda = "auto")
par(mfrow=c(1,2))
Acf(mod3$residuals,lag.max = 80) 
Pacf(mod3$residuals,lag.max = 80)
summary(mod3)
```
Come avevamo già supposto dall'analisi delle radici, anche dai correlogrammi e dalle misure di bontà risulta che l'aggiunta dell'integrazione peggiora il modello.


Proviamo a fare un primo plot di come il semplice modello ARIMA(6,0,7)(1,1,1)[7] preveda i dati del test set.
```{r, fig.height=5,fig.width=10}

pred <- forecast(mod2, h=730)

autoplot(shift_ts) +
  autolayer(pred,series="Fit") +
  autolayer(test_ts, series="Data") +
  xlab("Time") +
  ylab("Value")+
  ggtitle('ARIMA(6,0,7)(1,1,1)[7] VS real data')

```



Il passo successivo quindi consiste nell'aggiunta di regressori esterni. Consideriamo quindi l'aggiunta di armoniche.
```{r}
k <- 24
freq <- outer(1:nrow(data), 1:k)*2*pi/365.25    

cos <- cos(freq)                   
colnames(cos) <- paste("cos", 1:k)
sin <- sin(freq)                   
colnames(sin) <- paste("sin", 1:k)
reg <- as.matrix(cbind(cos,sin))


mod_reg <- Arima(train, c(6,0,7), list(order=c(1,1,1), period=7), 
              xreg=reg[1:(length(train)),], include.constant = T, lambda = "auto", method = "CSS")

ggtsdisplay(mod_reg$residuals, lag.max = 80)
summary(mod_reg)

```

Un passo ulteriore consiste nell'andare a considerare le festività italiane. Questo viene fatto grazie alla libreria RQuantLib
```{r}
load_quantlib_calendars("Italy", from = "2010-01-01", to = "2018-12-31") 

k <- 24

freq <- outer(1:nrow(data), 1:k)*2*pi/365.25    

cos <- cos(freq)                   
colnames(cos) <- paste("cos", 1:k)
sin <- sin(freq)                   
colnames(sin) <- paste("sin", 1:k)
reg_hol <- as.matrix(cbind(cos,sin))


data.frame(Data=data$Data) %>%
    mutate(holiday = as.numeric(!is.bizday(Data, "QuantLib/Italy")))%>%
    select(-starts_with("Data")) %>% 
    cbind(reg_hol) %>% 
    as.matrix() -> reg_hol


mod_reg_holidays <- Arima(train, c(6,0,7), list(order=c(1,1,1), period=7), 
              xreg=reg_hol[1:(length(train)),], include.constant = T, lambda = "auto", method = "CSS")

ggtsdisplay(mod_reg_holidays$residuals, lag.max = 80)
summary(mod_reg_holidays)

```
Questo secondo modello, che considera anche le festività, è migliore del primo sia in termini di log-likelihood che di AIC e MAPE sul training set.


Confrontiamo ora i due modelli sul test set graficamente e in termini di MAPE:
```{r, fig.height=5,fig.width=10}

pred <- forecast(mod_reg, h=730,
          xreg=reg[(length(train)+1):(length(train)+730),])

  
ggplot() +
autolayer(pred,series="Fit",size=1) +
autolayer(test_ts, series="Data",size=1) +
xlab("Time") +
ylab("Value")+
ggtitle('ARIMA(6,0,7)(1,1,1)[7] with harmonics VS real data')

print(MAPE(pred$mean, test_ts))
  
```


```{r, fig.height=5,fig.width=10}

pred <- forecast(mod_reg_holidays, h=730,
          xreg=reg_hol[(length(train)+1):(length(train)+730),])

  
ggplot() +
autolayer(pred,series="Fit",size=1) +
autolayer(test_ts, series="Data",size=1) +
xlab("Time") +
ylab("Value")+
ggtitle('ARIMA(6,0,7)(1,1,1)[7] with harmonics and holiday dummies VS real data')
  
print(MAPE(pred$mean, test_ts))
```
Dal confronto tra i due modelli risulta che quello con le sole armoniche riesce a fittare meglio i dati del test set. Quello che considera anche le festività probabilmente soffre di overfitting sul training set.


Consideriamo quindi il primo come migliore e utilizziamolo per effettuare previsioni dal 1-Gen-2019 al 30-Nov-2019:
```{r}
k <- 24
freq <- outer(1:(nrow(data)+365), 1:k)*2*pi/365.25

cos <- cos(freq)                   
colnames(cos) <- paste("cos", 1:k)
sin <- sin(freq)                   
colnames(sin) <- paste("sin", 1:k)
reg_fin <- as.matrix(cbind(cos,sin))


mod_reg_fin <- Arima(ts, c(6,0,7), list(order=c(1,1,1), period=7), 
              xreg=reg_fin[1:(length(ts)),], include.constant = T, lambda = "auto", method = "CSS")

```


```{r, fig.height=6,fig.width=11}
pred <- forecast(mod_reg_fin, h=334, xreg=reg_fin[(length(ts)+1):(length(ts)+334),])
pred_Arima<- pred$mean

autoplot(pred,include=300)+
  xlab("Time") +
  ylab("Value")+
ggtitle('Forecast with ARIMA(6,0,7)(1,1,1)[7]')
```




########################## UCM ########################## 




Proveremo diversi modelli UCM: un primo modello con LLT più regressori stagionali, un ILLT  e un LLT stimato come RW.
Il primo modello UCM è quindi un Local Linear Trend più dummies che considerino la stagionalità settimanale e armoniche per quella annua.
```{r}
ytrain <- as.numeric(train)
mod1 <- SSModel(ytrain ~ SSMtrend(2, list(NA,NA)) +
                      SSMseasonal(7, NA, "dummy") +
                      SSMseasonal(365, NA, "trig",
                      harmonics = 1:24),
                      H = NA)

#condizioni iniziali
vary <- var(ytrain, na.rm = TRUE)
mod1$P1inf <- mod1$P1inf * 0
mod1$a1[1] <- mean(ytrain, na.rm = TRUE)
diag(mod1$P1) <- vary



# Initial values for the variances we have to estimate
init <- numeric(5)
init[1] <- log(vary/10) 
init[2] <- log(vary/10) 
init[3] <- log(vary/100)
init[4] <- log(vary/100)
init[5] <- log(vary/10) 

#updating function
update_fun <- function(pars, model){
    model$Q[1, 1, 1] <- exp(pars[1])
    model$Q[2, 2, 1] <- exp(pars[2])
    model$Q[3, 3, 1] <- exp(pars[3])
    diag(model$Q[4:51,4:51, 1]) <- exp(pars[4])
    model$H[1, 1, 1] <- exp(pars[5])
    model
}

fit1 <- fitSSM(mod1, init, update_fun, control = list(maxit = 1000))
cat("Codice di convergenza = ",fit1$optim.out$convergence)
cat("\nMAPE on train: ",MAPE(fitted(fit1$model),ytrain))
```
0 indica la convergenza dell'algoritmo.

```{r}
smo1 <- KFS(fit1$model, smoothing = "state")
plot(timeSeries(ytrain, as.Date("2010-01-01") + 0:(length(ytrain)-1)))
lines(timeSeries(smo1$alphahat[, "level"], as.Date("2010-01-01") + 0:(length(ytrain)-1)),col = "red")
      
```


Facciamo previsioni one-step-ahead sul test set:
```{r, fig.height=5,fig.width=13}
y <- c(ytrain, rep(NA,length(test)))

mod1_test <- SSModel(y ~  SSMtrend(2, list(fit1$model$Q[1,1,1],fit1$model$Q[2,2,1])) +
                      SSMseasonal(7, fit1$model$Q[3,3,1], "dummy") +
                      SSMseasonal(365, fit1$model$Q[4, 4, 1], "trig",
                      harmonics = 1:24),
                      H = fit1$model$H)

mod1_test$a1 <- fit1$model$a1
mod1_test$P1 <- fit1$model$P1
mod1_test$P1inf <- fit1$model$P1inf

# Smoothing delle variabili di stato e segnale
smo1_ <- KFS(mod1_test, smoothing = c("state", "signal"))


pred <- smo1_$muhat[(length(train)+1):(length(ts)), 1]

ggplot() +
autolayer(test_ts,series="Data",size=1) + 
autolayer(ts(pred, start = length(ytrain)+1), series="Fit",size=1)+
xlab("Time") +
ylab("Value")+
ggtitle('Simple LLT VS real data')

print(MAPE(pred, test_ts))
```


Il secondo modello UCM è un Integrated Local Linear Trend:
```{r}
ytrain <- as.numeric(train)
mod2 <- SSModel(ytrain ~ SSMtrend(2, list(0,NA)) +
                      SSMseasonal(7, NA, "dummy") +
                      SSMseasonal(365, NA, "trig",
                      harmonics = 1:24),
                      H = NA)

#condizioni iniziali
vary <- var(ytrain, na.rm = TRUE)
mod2$P1inf <- mod2$P1inf * 0
mod2$a1[1] <- mean(ytrain, na.rm = TRUE)
diag(mod2$P1) <- vary



# Initial values for the variances we have to estimate
init <- numeric(5)
init[1] <- 0
init[2] <- log(vary/10) 
init[3] <- log(vary/100)
init[4] <- log(vary/100)
init[5] <- log(vary/10)

#updating function
update_fun <- function(pars, model){
    model$Q[1, 1, 1] <- exp(pars[1])
    model$Q[2, 2, 1] <- exp(pars[2])
    model$Q[3, 3, 1] <- exp(pars[3])
    diag(model$Q[4:51,4:51, 1]) <- exp(pars[4])
    model$H[1, 1, 1] <- exp(pars[5])
    model
}

fit2 <- fitSSM(mod2, init, update_fun, control = list(maxit = 1000))
cat("Codice di convergenza = ",fit2$optim.out$convergence)
cat("\nMAPE on train: ",MAPE(fitted(fit2$model),ytrain))
```


```{r}
smo2 <- KFS(fit2$model, smoothing = "state")
plot(timeSeries(ytrain, as.Date("2010-01-01") + 0:(length(ytrain)-1)))
lines(timeSeries(smo2$alphahat[, "level"], as.Date("2010-01-01") + 0:(length(ytrain)-1)),col = "red")
```


Previsioni one-step-ahead sul test set:
```{r, fig.height=5,fig.width=13}
y <- c(ytrain, rep(NA,length(test)))

mod2_test <- SSModel(y ~  SSMtrend(2, list(0,fit2$model$Q[2,2,1])) +
                      SSMseasonal(7, fit2$model$Q[3,3,1], "dummy") +
                      SSMseasonal(365, fit2$model$Q[4, 4, 1], "trig",
                      harmonics = 1:24),
                      H = fit2$model$H)

mod2_test$a1 <- fit2$model$a1
mod2_test$P1 <- fit2$model$P1
mod2_test$P1inf <- fit2$model$P1inf

# Smoothing delle variabili di stato e segnale
smo1_ <- KFS(mod2_test, smoothing = c("state", "signal"))


pred <- smo1_$muhat[(length(train)+1):(length(ts)), 1]

ggplot() +
autolayer(test_ts,series="Data",size=1) + 
autolayer(ts(pred, start = length(ytrain)+1), series="Fit",size=1)+
xlab("Time") +
ylab("Value")+
ggtitle('ILLT VS real data')

print(MAPE(pred, test_ts))
```


Per il terzo modello consideriamo un Random Walk:
```{r}
ytrain <- as.numeric(train)
mod3 <- SSModel(ytrain ~ SSMtrend(1, NA) +
                      SSMseasonal(7, NA, "dummy") +
                      SSMseasonal(365, NA, "trig",
                      harmonics = 1:24),
                      H = NA)

#condizioni iniziali
vary <- var(ytrain, na.rm = TRUE)
mod3$P1inf <- mod3$P1inf * 0
mod3$a1[1] <- mean(ytrain, na.rm = TRUE)
diag(mod3$P1) <- vary



# Initial values for the variances we have to estimate
init <- numeric(5)
init[1] <- log(vary/10) 
init[2] <- log(vary/100)
init[3] <- log(vary/100)
init[4] <- log(vary/10) 

#updating function
update_fun <- function(pars, model){
    model$Q[1, 1, 1] <- exp(pars[1])
    model$Q[2, 2, 1] <- exp(pars[2])
    diag(model$Q[3:50, 3:50, 1]) <- exp(pars[3])
    model$H[1, 1, 1] <- exp(pars[4])
    model
}


fit3 <- fitSSM(mod3, init, update_fun, control = list(maxit = 1000))
cat("Codice di convergenza = ",fit3$optim.out$convergence)
cat("\nMAPE on train: ",MAPE(fitted(fit3$model),ytrain))
```


```{r}
smo3 <- KFS(fit3$model, smoothing = "state")
plot(timeSeries(ytrain, as.Date("2010-01-01") + 0:(length(ytrain)-1)))
lines(timeSeries(smo3$alphahat[, "level"], as.Date("2010-01-01") + 0:(length(ytrain)-1)),col = "red")
```


Previsioni one-step.ahead sul test set:
```{r, fig.height=5,fig.width=13}
y <- c(ytrain, rep(NA,length(test)))

mod3_test <- SSModel(y ~  SSMtrend(1, fit3$model$Q[1,1,1]) +
                      SSMseasonal(7, fit3$model$Q[2,2,1], "dummy") +
                      SSMseasonal(365, fit3$model$Q[3, 3, 1], "trig",
                      harmonics = 1:24),
                      H = fit3$model$H)

mod3_test$a1 <- fit3$model$a1
mod3_test$P1 <- fit3$model$P1
mod3_test$P1inf <- fit3$model$P1inf

# Smoothing delle variabili di stato e segnale
smo1_ <- KFS(mod3_test, smoothing = c("state", "signal"))


pred <- smo1_$muhat[(length(train)+1):(length(ts)), 1]

ggplot() +
autolayer(test_ts,series="Data",size=1) + 
autolayer(ts(pred, start = length(ytrain)+1), series="Fit",size=1)+
xlab("Time") +
ylab("Value")+
ggtitle('RW VS real data')

print(MAPE(pred, test_ts))
```


Questo terzo modello Random Walk è quello che in termini di MAPE performa meglio. Sarà quindi questo ad essere utilizzato per effettuare la previsione dei valori dal 1-Gen-2019 al 30-Nov-2019:
```{r, fig.height=6,fig.width=11}
y <- c(as.numeric(ts), rep(NA,334))

mod_ucm_fin <- SSModel(y ~  SSMtrend(1, fit3$model$Q[1,1,1]) +
                      SSMseasonal(7, fit3$model$Q[2,2,1], "dummy") +
                      SSMseasonal(365, fit3$model$Q[3, 3, 1], "trig",
                      harmonics = 1:24),
                      H = fit3$model$H)

mod_ucm_fin$a1 <- fit3$model$a1
mod_ucm_fin$P1 <- fit3$model$P1
mod_ucm_fin$P1inf <- fit3$model$P1inf

smo_fin <- KFS(mod_ucm_fin, smoothing = c("state", "signal"))

pred_ucm <- smo_fin$muhat[(length(train)+length(test)+1):(length(y)), 1]

autoplot(ts(test, start = length(train)+1+430, end = length(test)+length(train),frequency = frequency(test)),size=0.7) +
autolayer(ts(pred_ucm, start = (length(train)+length(test)+1)), series="Forecast",size=1)+
xlab("Time") +
ylab("Value")+
ggtitle('Forecast with RW')
```


Esportiamo quindi i dati delle previsioni in un dataframe:
```{r}
dataframe_pred <- data.frame(matrix(ncol = 4, nrow = 334))
colnames(dataframe_pred) <- c("Data", "ARIMA", "UCM", "ML")
dataframe_pred$Data <- seq(as.Date("2019-01-01"),as.Date("2019-11-30"),1)
dataframe_pred$ARIMA <- pred_Arima
dataframe_pred$UCM <- pred_ucm

write.csv(dataframe_pred, file="SDMTSA_790544_1.csv", sep = ";", dec = ".", row.names=FALSE)
```




